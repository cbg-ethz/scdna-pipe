from scgenpy import *
from scgenpy.preprocessing.utils import *

from scicone import SCICoNE, Tree

import glob
import os
import h5py
import subprocess
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from tqdm import tqdm
from pathlib import Path
from collections import Counter
import re
import warnings
sns.set_style("ticks")

scicone_path = config['scicone_path']
output_temp_path = config['output_temp_path']

bin_size = config['bin_size']
fastqs_path = config['fastqs_path']
moved_fastqs_path = os.path.join(fastqs_path, "merged", "tricked")
analysis_path = config['analysis_path']

analysis_prefix = config['analysis_prefix']
seq_prefix = config["sequencing_prefix"]

to_upload_path = os.path.join(analysis_path, '..', 'to_upload', analysis_prefix)
sym_raw_path = os.path.join(to_upload_path, "raw")
sym_derived_path = os.path.join(to_upload_path, "derived")
cellranger_path = os.path.join(analysis_path, "cellranger")
scripts_dir = config['scripts_dir']+'/'
raw_fastqs = glob.glob(fastqs_path + "*.fastq.gz")
n_lanes = config['n_lanes']
fastq_lanes = [f"L00{i}" for i in range(1, n_lanes+1)]
sample_name = config['sample_name']
cr_sample_name = sample_name[:-3] # e.g. MHELAVELA_S2 becomes MHELAVELA
h5_path = config['secondary_analysis']['h5_path']
gene_lists_path = config['secondary_analysis']['genes_path']
gene_coordinates_path = os.path.join(gene_lists_path, 'ensembl_hg19_annotations.tsv')
disease_genes_path = os.path.join(gene_lists_path, 'disease_specific', f"{config['disease']}_genes.txt")
general_main_gene_list_path = os.path.join(gene_lists_path, 'general', f"{config['secondary_analysis']['general_main_gene_list']}")

try:
    tree_rep = config["inference"]["cluster_trees"]["n_reps"]
except KeyError:
    tree_rep = 10

derived_file_names = [
            "cnv_data.h5",
            "web_summary.html",
            "summary.csv",
            "alarms_summary.txt",
            "chr_stops.tsv",
            "bins_genome.tsv",
            "filtered_counts.csv",
            "excluded_bins.csv",
            "segmented_regions.txt",
            "segmented_region_sizes.txt",
            "segmented_counts.csv",
            "normalised_bins.csv",
            "normalised_regions.csv",
            "clustering_score.txt",
            "cluster_tree.txt",
            "cluster_tree_sorted_normalised_counts_bins.png",
            "cluster_tree_sorted_cnvs_bins.png",
            "unique_cluster_tree_cnvs.csv",
            "inferred_cnvs.csv",
            "cluster_tree_tree_node_sizes.csv",
            "cluster_tree_genes.png",
            "cluster_profile_files.txt",
            "cluster_profile_overlapping.png",
            "cn_gene_df.csv",
            "cn_gene_df_roche_gene_list.csv",
            "heatmap_cnvs.png",
            "Summary.txt"
        ]

tree_outputs = ["cluster_tree"]

sa = SecondaryAnalysis(
    sample_name=analysis_prefix,
    output_path=analysis_path,
    h5_path=h5_path
)

# import rules
include: os.path.join(workflow.basedir, "rules", "tree_learning.smk")
include: os.path.join(workflow.basedir, "rules", "breakpoint_detection.smk")
include: os.path.join(workflow.basedir, "rules", "process_cnvs.smk")
include: os.path.join(workflow.basedir, "rules", "plotting.smk")

onstart:
    print(f"Workflow main directory: {workflow.basedir}")

rule all:
    input:
        # checksums
        raw_checksum_file = os.path.join(sym_raw_path, f"{seq_prefix}__raw_files.md5"),
        derived_checksum_file = os.path.join(sym_derived_path, f"{analysis_prefix}__derived_files.md5"),
        robustness_results = expand(os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__{tree_name}_robustness.txt", tree_name=tree_outputs),
        bin_chr_indicator = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bin_chr_indicator.txt",
        # cn_cluster_h5 = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_cluster.h5"
    run:
        print("echo rule all")

rule remove_tenx_artifacts:
    params:
        bins = config["secondary_analysis"]["bins_to_remove"]
    input:
        os.path.join(cellranger_path, cr_sample_name) + "/outs/cnv_data.h5"
    output:
        filtered_counts = os.path.join(analysis_path, "filtering", analysis_prefix) + "__filtered_counts.csv",
        filtered_counts_shape = os.path.join(analysis_path, "filtering", analysis_prefix) + "__filtered_counts_shape.txt",
        excluded_bins = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv",
    run:
        sa.remove_tenx_genomics_artifacts(bins=params.bins)

rule extract_genomic_info:
    params:
        gender = config['gender']
    input:
        os.path.join(cellranger_path, cr_sample_name) + "/outs/cnv_data.h5"
    output:
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv",
        bin_chr_indicator = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bin_chr_indicator.txt",
        bins_genome = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bins_genome.tsv"
    benchmark:
        "benchmark/extract_genomic_info.tsv"
    run:
        sa.extract_genomic_info(params.gender)

rule add_filtered_bins_back:
    input:
        cnv_profiles = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_inferred_cnvs.csv", # use cluster tree results
        unique_cnv_profiles = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__unique_cluster_tree_cnvs.csv", # use cluster tree results
        excluded_bins = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv"
    output:
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        unique_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__unique_cnvs.csv"
    benchmark:
        "benchmark/add_filtered_bins_back.tsv"
    run:
        sa.add_filtered_bins_back(input.cnv_profiles, input.excluded_bins, output.inferred_cnvs)
        sa.add_filtered_bins_back(input.unique_cnv_profiles, input.excluded_bins, output.unique_cnvs)

rule merge_files:
    params:
        fastqs_path = fastqs_path,
        n_lanes = n_lanes,
	scripts_dir = scripts_dir
    input:
        raw_fastqs = expand('{sample}', sample=raw_fastqs)
    output:
        done = "merge_files_done.txt"
    shell:
        "sh {params.scripts_dir}/merge_10x_gzip_files.sh {params.fastqs_path} {params.n_lanes}; \
	if [ -d {params.fastqs_path}/merged ] ; \
	then \
	    echo merged directory exists;\
	else \
	    mkdir {params.fastqs_path}/merged;\
	fi ; \
        mv {params.fastqs_path}/MERGED_BSSE* {params.fastqs_path}/merged;\
        chmod 775 {params.fastqs_path}/merged/*;\
	touch merge_files_done.txt"


rule rename_fastqs:
    input:
        rules.merge_files.output.done
    output:
        "rename_fastqs_done.txt"
    run:
        merged_fastqs_path = fastqs_path + "/merged/"
    	print(merged_fastqs_path)
    	fastqs_dir = merged_fastqs_path
    	for filename in os.listdir(fastqs_dir):
    	    if filename.startswith("MERGED_BSSE") and filename.endswith('.gz'):
    	        print("old name: " + filename)
                print("new name: " + rename_fastq(filename))
                os.rename(fastqs_dir+filename, fastqs_dir+rename_fastq(filename, sample_name=sample_name))
        Path('rename_fastqs_done.txt').touch()

rule trick_fastqs:
    params:
        fastqs_path = fastqs_path,
        scripts_dir = scripts_dir,
        r1 = fastqs_path+"/merged/" + sample_name + "_" + "{lane_no}" + "_R1_001.fastq.gz",
        r2 = fastqs_path+"/merged/" + sample_name + "_" + "{lane_no}" + "_R2_001.fastq.gz",
        mem = config["tricking_fastqs"]["mem"],
        time = config["tricking_fastqs"]["time"],
        insert_length = config["tricking_fastqs"]["insert_length"]
    input:
        rules.rename_fastqs.output
    output:
        r1_fastqs = os.path.join(moved_fastqs_path, sample_name) + "_" + "{lane_no}" + "_R1_001.fastq.gz"
    shell:
        "\
        if [ -d {params.fastqs_path}/merged/tricked ] ; \
        then \
        echo tricked directory exists;\
        else \
        mkdir {params.fastqs_path}/merged/tricked;\
        fi ;\
        python {params.scripts_dir}/cellranger_dna_trick.py -r1 {params.r1}  -r2 {params.r2} -l {params.insert_length} -o {params.fastqs_path}/merged/tricked/"

rule move_fastqs:
    params:
        fastqs_path = fastqs_path,
        sample_name = sample_name
    input:
        tricked_fastqs = expand(os.path.join(moved_fastqs_path, sample_name) + "_" + "{lane_no}" + "_R1_001.fastq.gz", lane_no = fastq_lanes)
    output:
        move_after_tricking_fastqs = "move_fastqs_to_tricked_done.txt"
    shell:
        "mv {params.fastqs_path}/merged/*_R2_* {params.fastqs_path}/merged/tricked/;\
             mv {params.fastqs_path}/merged/*_I1_* {params.fastqs_path}/merged/tricked/;\
                  chmod 755 {params.fastqs_path}/merged/tricked/*;\
                      touch move_fastqs_to_tricked_done.txt;"

rule create_raw_files_list:
    params:
        sym_raw_path = sym_raw_path,
        seq_prefix = seq_prefix
    input:
        sym_r1_fastqs = expand(os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R1_001.fastq.gz", lane_no = fastq_lanes),
        sym_r2_fastqs = expand(os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R2_001.fastq.gz", lane_no = fastq_lanes),
        sym_i1_fastqs = expand(os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_I1_001.fastq.gz", lane_no = fastq_lanes)
    output:
        os.path.join(sym_raw_path, seq_prefix) + "__raw_files.txt"
    shell:
        "cd {params.sym_raw_path}; ls > {params.seq_prefix}__raw_files.txt "

rule create_raw_checksum:
    params:
        sym_raw_path = sym_raw_path,
        seq_prefix = seq_prefix
    input:
        os.path.join(sym_raw_path, seq_prefix) + "__raw_files.txt"
    output:
        checksum_file = os.path.join(sym_raw_path, seq_prefix) + "__raw_files.md5"
    shell:
        "cd {params.sym_raw_path}; find . -exec md5sum '{{}}' \; >  {output.checksum_file}"

rule run_cellranger:
    params:
        fastqs_path = fastqs_path+'/merged/tricked',
        cr_sample_name = cr_sample_name,
        cellranger_path = cellranger_path,
        local_cores = config['cellranger_dna']['local_cores'],
        local_mem = config['cellranger_dna']['local_mem'],
        mem_per_core = config['cellranger_dna']['mem_per_core'],
        mem = config['cellranger_dna']['mem'],
        time = config['cellranger_dna']['time']
    input:
        move_after_tricking_fastqs = "move_fastqs_to_tricked_done.txt",
        reference_path = config['ref_genome_path']
    output:
        cnv_data = os.path.join(cellranger_path, cr_sample_name) + "/outs/cnv_data.h5",
        cellranger_done = "cellranger_done.txt"
    shell:
        'if [ -d {params.cellranger_path}/run ] ; \
        then \
        echo cellranger directory exists;\
        else \
        mkdir {params.cellranger_path}/run;\
        fi ;\
         pushd {params.cellranger_path}/run; cellranger-dna cnv --reference={input.reference_path} --fastqs={params.fastqs_path}\
         --localmem={params.local_mem} --localcores={params.local_cores} --mempercore={params.mem_per_core}\
         --id={params.cr_sample_name} --sample={params.cr_sample_name}; ln -s "{params.cellranger_path}/run/{params.cr_sample_name}/outs/cnv_data.h5"\
         "{params.cellranger_path}/{params.cr_sample_name}/outs/cnv_data.h5"; popd; touch cellranger_done.txt'

rule copy_cellranger_outputs:
    params:
        cr_sample_name = cr_sample_name,
        cellranger_path = cellranger_path,
        analysis_prefix = analysis_prefix
    input:
        cellranger_done = "cellranger_done.txt"
    output:
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__alarms_summary.txt",
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__cnv_data.h5",
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__summary.csv",
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__web_summary.html"
    shell:
        "cd {params.cellranger_path}; \
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/cnv_data.h5'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__cnv_data.h5';\
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/alarms_summary.txt'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__alarms_summary.txt';\
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/summary.csv'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__summary.csv';\
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/web_summary.html'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__web_summary.html';"

rule create_cluster_plots_list:
    params:
        analysis_prefix = analysis_prefix,
        analysis_path = analysis_path
    input:
        secondary_analysis_done = "secondary_analysis_done.txt"
    output:
        cluster_plots_list = os.path.join(analysis_path, "clustering", analysis_prefix ) + "__cluster_profile_files.txt"
    shell:
        "cd {params.analysis_path}/clustering; ls | egrep '{params.analysis_prefix}__cluster_profile_..?\.png' > {params.analysis_prefix}__cluster_profile_files.txt"

rule create_heatmap_plots_list:
    params:
        analysis_prefix = analysis_prefix,
        analysis_path = analysis_path
    input:
        secondary_analysis_done = "secondary_analysis_done.txt"
    output:
        heatmap_plots_list = os.path.join(analysis_path, "clustering", analysis_prefix ) + "__cn_genes_clusters_files.txt"
    shell:
        "cd {params.analysis_path}/clustering; ls | egrep '{params.analysis_prefix}__cn_genes_clusters_chr..?_heatmap\.png' > {params.analysis_prefix}__cn_genes_clusters_files.txt"

rule create_raw_symlinks:
    params:
        seq_prefix = seq_prefix,
        sym_raw_path = sym_raw_path,
        moved_fastqs_path = moved_fastqs_path,
        sample_name = sample_name,
        old_file_name = os.path.join(moved_fastqs_path, sample_name ) + "_"
    input:
        cellranger = "cellranger_done.txt",
        r1_fastqs = os.path.join(moved_fastqs_path, sample_name ) + "_" + "{lane_no}" + "_R1_001.fastq.gz",
        move_after_tricking_fastqs = "move_fastqs_to_tricked_done.txt"
        # r2_fastqs = os.path.join(moved_fastqs_path, sample_name ) + "_" + "{lane_no}" + "_R2_001.fastq.gz",
        # i1_fastqs = os.path.join(moved_fastqs_path, sample_name ) + "_" + "{lane_no}" + "_I1_001.fastq.gz"
    output:
        r1_fastqs = os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R1_001.fastq.gz",
        r2_fastqs = os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R2_001.fastq.gz",
        i1_fastqs = os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_I1_001.fastq.gz"
    shell:
        "ln -s {input.r1_fastqs} {output.r1_fastqs};\
            ln -s {params.old_file_name}{wildcards.lane_no}_R2_001.fastq.gz {output.r2_fastqs};\
                ln -s {params.old_file_name}{wildcards.lane_no}_I1_001.fastq.gz {output.i1_fastqs};"

rule create_derived_symlinks:
    params:
        cellranger_path = cellranger_path,
        analysis_prefix = analysis_prefix,
        ploidy = config["inference"]["ploidy"]
    input:
        cellranger = "cellranger_done.txt",
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv",
        bins_genome = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bins_genome.tsv",
        filtered_counts = os.path.join(analysis_path, "filtering", analysis_prefix ) + "__filtered_counts.csv",
        excluded_bins = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv",
        segmented_regions = os.path.join(analysis_path, "breakpoint_detection", analysis_prefix) + "_segmented_regions.txt",
        segmented_region_sizes = os.path.join(analysis_path, "breakpoint_detection", analysis_prefix) + "_segmented_region_sizes.txt",
        segmented_counts = os.path.join(analysis_path,\
        "breakpoint_detection", analysis_prefix) + "_segmented_counts.csv",
        normalised_bins = os.path.join(analysis_path, "normalisation", analysis_prefix) + "__normalised_bins.csv",
        normalised_regions = os.path.join(analysis_path, "normalisation", analysis_prefix) + "__normalised_regions.csv",
        clustering_score = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__clustering_score.txt",
        cluster_tree = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.txt",
        cluster_tree_inferred_cnvs = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_inferred_cnvs.csv",
        cluster_tree_sorted_normalised_counts_bins = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cluster_tree_sorted_normalised_counts_bins.png",
        cluster_tree_sorted_cnvs_bins = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cluster_tree_sorted_cnvs_bins.png",
        unique_cnv_profiles = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__unique_cluster_tree_cnvs.csv",
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        cluster_tree_tree_node_sizes =  os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_tree_node_sizes.csv",
        cluster_tree_genes_png = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_genes.png",
        overlapping_cluster_plot = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cluster_profile_overlapping.png",
        gene_cn_df = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_gene_df.csv",
        gene_cn_df_roche_gene_list = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_gene_df_roche_gene_list.csv",
        heatmap_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__heatmap_cnvs.png",
        cr_alarms_summary = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__alarms_summary.txt",
        cr_cnv_data = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__cnv_data.h5",
        cr_summary = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__summary.csv",
        cr_web_summary = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__web_summary.html",

    output:
        derived_symlinks = [os.path.join(sym_derived_path, f"{analysis_prefix}__{filename}") for filename in derived_file_names]
    run:

        def create_symlink(source, dest):
            if not os.path.isfile(dest):
                os.symlink(source, dest)
            else:
                os.utime(dest, None)  # Set access/modified times to now

        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__cnv_data.h5", os.path.join(sym_derived_path, f"{analysis_prefix}__cnv_data.h5"))
        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__alarms_summary.txt", os.path.join(sym_derived_path, f"{analysis_prefix}__alarms_summary.txt"))
        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__summary.csv", os.path.join(sym_derived_path, f"{analysis_prefix}__summary.csv"))
        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__web_summary.html", os.path.join(sym_derived_path, f"{analysis_prefix}__web_summary.html"))

        create_symlink(input.chr_stops, os.path.join(sym_derived_path, f"{analysis_prefix}__chr_stops.tsv"))
        create_symlink(input.bins_genome, os.path.join(sym_derived_path, f"{analysis_prefix}__bins_genome.tsv"))
        create_symlink(input.filtered_counts, os.path.join(sym_derived_path, f"{analysis_prefix}__filtered_counts.csv"))

        create_symlink(input.excluded_bins, os.path.join(sym_derived_path, f"{analysis_prefix}__excluded_bins.csv"))

        create_symlink(input.segmented_regions, os.path.join(sym_derived_path, f"{analysis_prefix}__segmented_regions.txt"))
        create_symlink(input.segmented_region_sizes, os.path.join(sym_derived_path, f"{analysis_prefix}__segmented_region_sizes.txt"))
        create_symlink(input.segmented_counts, os.path.join(sym_derived_path, f"{analysis_prefix}__segmented_counts.csv"))

        create_symlink(input.normalised_bins, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_bins.csv"))
        create_symlink(input.normalised_regions, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_regions.csv"))

        create_symlink(input.cluster_tree_sorted_normalised_counts_bins, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_tree_sorted_normalised_counts_bins.png"))
        create_symlink(input.cluster_tree_sorted_cnvs_bins, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_tree_sorted_cnvs_bins.png"))

        create_symlink(input.clustering_score, os.path.join(sym_derived_path, f"{analysis_prefix}__clustering_score.txt"))
        create_symlink(input.clusters_phenograph_assignment, os.path.join(sym_derived_path, f"{analysis_prefix}__clusters_phenograph_assignment.tsv"))

        create_symlink(input.avg_counts, os.path.join(sym_derived_path, f"{analysis_prefix}__avg_counts.csv"))
        create_symlink(input.cluster_tree, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_tree.txt"))
        create_symlink(input.cluster_tree_inferred_cnvs, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_tree_inferred_cnvs.csv"))
        create_symlink(input.unique_cnv_profiles, os.path.join(sym_derived_path, f"{analysis_prefix}__unique_cluster_tree_cnvs.csv"))
        create_symlink(input.inferred_cnvs, os.path.join(sym_derived_path, f"{analysis_prefix}__inferred_cnvs.csv"))
        create_symlink(input.cluster_tree_genes_png, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_tree_genes.png"))

        create_symlink(input.tree_cluster_sizes, os.path.join(sym_derived_path, f"{analysis_prefix}__tree_cluster_sizes.txt"))
        create_symlink(input.overlapping_cluster_plot, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_profile_overlapping.png"))

        cluster_profile_plots = glob.glob(os.path.join(analysis_path, "inferred_cnvs", f"{analysis_prefix}__cluster_profile_[0-9]*.png"))
        print(cluster_profile_plots)
        with open(os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_profile_files.txt"), "w") as file:
            for cluster_profile_plot in cluster_profile_plots:
                f_name = cluster_profile_plot.split("/")[-1]
                create_symlink(cluster_profile_plot, os.path.join(sym_derived_path, f"{f_name}"))
                file.write(f"{f_name}\n")

        create_symlink(input.gene_cn_df, os.path.join(sym_derived_path, f"{analysis_prefix}__cn_gene_df.csv"))
        create_symlink(input.gene_cn_df_roche_gene_list, os.path.join(sym_derived_path, f"{analysis_prefix}__cn_gene_df_roche_gene_list.csv"))
        create_symlink(input.heatmap_cnvs, os.path.join(sym_derived_path, f"{analysis_prefix}__heatmap_cnvs.png"))

        # write the summary txt
        cn_gene_df = pd.read_csv(input.gene_cn_df, index_col=0)
        if 'is_imputed' in cn_gene_df.columns:
            cn_gene_df = cn_gene_df.drop(columns=['is_imputed'])
        n_clusters = len(cn_gene_df.columns)

        segmented_counts = np.loadtxt(input.segmented_counts, delimiter=',')
        n_cells = segmented_counts.shape[0]

        amplified_genes = cn_gene_df[(cn_gene_df > params.ploidy).any(axis='columns')].index.values.tolist()
        n_amplified_genes = len(amplified_genes)
        amplified_genes = ', '.join(amplified_genes)
        deleted_genes = cn_gene_df[(cn_gene_df < params.ploidy).any(axis='columns')].index.values.tolist()
        n_deleted_genes = len(deleted_genes)
        deleted_genes = ', '.join(deleted_genes)

        open(os.path.join(sym_derived_path, f"{analysis_prefix}__Summary.txt"), "w").close()
        with open(os.path.join(sym_derived_path, f"{analysis_prefix}__Summary.txt"), "w") as summary_file:
            warning_str = ""
            if n_cells  > 2 and n_cells < 20:
                warning_str = f"Warning: only {n_cells} cells detected. These results may only be used to confirm results from other technologies.\n"
            if n_cells <=2:
                warning_str = f"Only {n_cells} cell(s) detected. No analysis performed.\n"

            summary_file.write(warning_str)

            if n_cells > 2:
                if n_clusters > 1:
                    verb = 'are'
                    clones = 'clones'
                else:
                    verb = 'is'
                    clones = 'clone'
                if n_amplified_genes > 0:
                    amp_str = f"copy number gains in {amplified_genes}"
                else:
                    amp_str = f"no copy number gains"
                if n_deleted_genes > 0:
                    del_str = f"copy number deletions in {deleted_genes}"
                else:
                    del_str = f"no copy number deletions"

                summary_file.write(f"There {verb} {n_clusters} {clones} detected with {amp_str}"
                f" and {del_str} among the pre-selected genes.")

rule create_derived_checksum:
    params:
        sym_derived_path = sym_derived_path,
        analysis_prefix = analysis_prefix,
    input:
        derived_symlinks = [os.path.join(sym_derived_path, f"{analysis_prefix}__{filename}") for filename in derived_file_names]
    output:
        checksum_file = os.path.join(sym_derived_path, f"{analysis_prefix}__derived_files.md5")
    shell:
        "cd {params.sym_derived_path}; find . -exec md5sum '{{}}' \; >  {output.checksum_file}"
