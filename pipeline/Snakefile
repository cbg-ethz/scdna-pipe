import glob
import os
import h5py
import subprocess
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm import tqdm
from pathlib import Path
from secondary_analysis import SecondaryAnalysis
from secondary_analysis.utils import *
from collections import Counter
import re
import warnings
sns.set()

bin_size = config['bin_size']
fastqs_path = config['fastqs_path']
moved_fastqs_path = os.path.join(fastqs_path, "merged", "tricked")
analysis_path = config['analysis_path']

to_upload_path = os.path.join(analysis_path, '..', 'to_upload')
sym_raw_path = os.path.join(to_upload_path, "raw")
sym_derived_path = os.path.join(to_upload_path, "derived")
cellranger_path = os.path.join(analysis_path, "cellranger")
scripts_dir = config['scripts_dir']+'/'
raw_fastqs = glob.glob(fastqs_path + "*.fastq.gz")
fastq_lanes = ["L001","L002","L003","L004"]
sample_name = config['sample_name']
cr_sample_name = sample_name[:-3] # e.g. MHELAVELA_S2 becomes MHELAVELA
h5_path = config['secondary_analysis']['h5_path']
genes_path = config['secondary_analysis']['genes_path']
all_genes_path = config['secondary_analysis']['all_genes_path']
important_genes_path = config['secondary_analysis']['important_genes_path']
roche_genes_path = config['secondary_analysis']['roche_genes_path']

analysis_prefix = config['analysis_prefix']
seq_prefix = config["sequencing_prefix"]

try:
    tree_rep = config["inference"]["cluster_trees"]["n_reps"]
except KeyError:
    tree_rep = 10

derived_file_names = [
            "cnv_data.h5",
            "web_summary.html",
            "summary.csv",
            "alarms_summary.txt",
            "chr_stops.tsv",
            "bins_genome.tsv",
            "filtered_counts.csv",
            "excluded_bins.csv",
            "segmented_regions.txt",
            "segmented_region_sizes.txt",
            "segmented_counts.csv",
            "normalised_bins.csv",
            "normalised_regions.csv",
            "normalised_bins_clustered.png",
            "normalised_bins_clustered_bps.png",
            "clusters_phenograph_assignment.tsv",
            "clustering_score.txt",
            "avg_counts.csv",
            "cluster_tree.txt",
            "cluster_tree_inferred_cnvs.csv",
            "unique_cluster_tree_cnvs.csv",
            "inferred_cnvs.csv",
            "tree_cluster_sizes.txt",
            "cluster_profile_files.txt",
            "cluster_profile_overlapping.png",
            "cn_gene_df.csv",
            "heatmap_cnvs.png",
            "Summary.txt"
        ]

tree_outputs = ["cluster_tree", "full_tree"]

sa = SecondaryAnalysis(
    sample_name=analysis_prefix,
    output_path=analysis_path,
    h5_path=h5_path,
    genes_path=genes_path,
    all_genes_path=all_genes_path,
)

# import rules
include: os.path.join(workflow.basedir, "rules", "tree_learning.smk")
include: os.path.join(workflow.basedir, "rules", "breakpoint_detection.smk")

onstart:
    print(f"Workflow main directory: {workflow.basedir}")

rule all:
    input:
        # checksums
        raw_checksum_file = os.path.join(sym_raw_path, f"{seq_prefix}__raw_files.md5"),
        derived_checksum_file = os.path.join(sym_derived_path, f"{analysis_prefix}__derived_files.md5"),
        robustness_results = expand(os.path.join(analysis_path, "tree_learning", analysis_prefix) + "_{tree_name}_robustness.txt", tree_name=tree_outputs),

        roche_gene_cn_df = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__roche_cn_gene_df.csv",
        roche_heatmap_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__roche_heatmap_cnvs.png",

        cluster_tree_graphviz = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.graphviz",
        cluster_tree_figure =  os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.png",

        cluster_tree_genes_graphviz = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_genes.graphviz",
        cluster_tree_genes_figure =  os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_genes.png",

        cn_cluster_h5 = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_cluster.h5"
    output:

    run:
        print("echo rule all")

rule remove_tenx_artifacts:
    params:
        bins = config["secondary_analysis"]["bins_to_remove"]
    input:
        os.path.join(cellranger_path, cr_sample_name) + "/outs/cnv_data.h5"
    output:
        filtered_counts = os.path.join(analysis_path, "filtering", analysis_prefix) + "__filtered_counts.csv",
        filtered_counts_shape = os.path.join(analysis_path, "filtering", analysis_prefix) + "__filtered_counts_shape.txt",
        excluded_bins = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv",
    run:
        sa.remove_tenx_genomics_artifacts(bins=params.bins)

rule extract_genomic_info:
    input:
        os.path.join(cellranger_path, cr_sample_name) + "/outs/cnv_data.h5"
    output:
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv",
        bins_genome = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bins_genome.tsv"
    benchmark:
        "benchmark/extract_genomic_info.tsv"
    run:
        sa.extract_genomic_info()

rule create_bin_gene_region_df:
    input:
        all_genes_path = all_genes_path,
        chr_stops_path = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv",
        excluded_bins_path = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv",
        region_stops_path = os.path.join(analysis_path, "breakpoint_detection", analysis_prefix) + "_segmented_regions.txt",
        important_genes_path = important_genes_path
    params:
        bin_size = bin_size
    output:
        bin_gene_region_df = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bin_gene_region_df.csv"
    benchmark:
        "benchmark/create_bin_gene_region_df.tsv"
    run:
        genes = pd.read_csv(input.all_genes_path, sep="\t")
        chr_stops = pd.read_csv(input.chr_stops_path, sep="\t", index_col=1)
        excluded_bins = pd.read_csv(input.excluded_bins_path, header=None)
        region_stops = pd.read_csv(input.region_stops_path, header=None)
        region_stops.columns = ["bin"]
        important_genes = pd.read_csv(input.important_genes_path, sep="\t", header=None)
        important_genes.columns = ["gene"]
        important_genes = important_genes.gene.values.tolist()

        df = get_bin_gene_region_df(params.bin_size, genes, chr_stops, region_stops, excluded_bins, important_genes=important_genes)
        df.to_csv(output.bin_gene_region_df)

rule add_filtered_bins_back:
    input:
        unique_cnv_profiles = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__unique_cluster_tree_cnvs.csv",
        excluded_bins = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv"
    output:
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv"
    benchmark:
        "benchmark/add_filtered_bins_back.tsv"
    run:
        sa.add_filtered_bins_back(input.unique_cnv_profiles, input.excluded_bins)

rule plot_cluster_cnvs:
    params:
    input:
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv"
    output:
        overlapping_cluster_plot = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cluster_profile_overlapping.png"
    benchmark:
        "benchmark/plot_cluster_cnvs.tsv"
    run:
        sa.plot_clusters(input.chr_stops, input.inferred_cnvs)

rule plot_heatmap:
    params:
        genes_path = config['secondary_analysis']['genes_path'],
        bin_size = bin_size
    input:
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv"
    output:
        gene_cn_df = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_gene_df.csv",
        heatmap_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__heatmap_cnvs.png"
    benchmark:
        "benchmark/plot_heatmap.tsv"
    run:
        cnvs_arr = np.loadtxt(input.inferred_cnvs, delimiter=',')
        genes = pd.read_csv(params.genes_path, sep="\t")
        chr_stops = pd.read_csv(input.chr_stops, sep="\t", index_col=1)
        gene_cn_df = get_gene_cn_df(genes, cnvs_arr, bin_size, chr_stops)

        gene_cn_df.to_csv(
            output.gene_cn_df
        )

        figure_width = gene_cn_df.shape[0] / 2 + 1.5
        plt.figure(figsize=(8, figure_width))
        cmap = sns.diverging_palette(220, 10, as_cmap=True)
        heatmap = sns.heatmap(
            gene_cn_df,
            annot=True,
            cmap=cmap,
            vmin=0,
            vmax=4,
            xticklabels=True,
            yticklabels=True,
            cbar_kws={"ticks": [0, 1, 2, 3, 4]},
        )
        heatmap.set_title("Copy number values of genes per cluster")
        heatmap.set_facecolor("#656565")
        heatmap = heatmap.get_figure()
        heatmap.savefig(
            output.heatmap_cnvs
        )
        plt.close()

rule create_cn_cluster_h5:
    params:
        all_genes_path = all_genes_path,
        bin_size = bin_size
    input:
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv"
    output:
        cn_cluster_h5 = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_cluster.h5"
    benchmark:
        "benchmark/create_cn_cluster_h5"
    run:
        cnvs_arr = np.loadtxt(input.inferred_cnvs, delimiter=',')
        genes = pd.read_csv(params.all_genes_path, sep="\t")
        chr_stops = pd.read_csv(input.chr_stops, sep="\t", index_col=1)

        gene_cn_df = get_gene_cn_df(genes, cnvs_arr, bin_size, chr_stops)

        cn_cluster_h5 = h5py.File(output.cn_cluster_h5, "w")
        gene_attributes = cn_cluster_h5.create_group("gene_attrs")
        gene_names = np.array(gene_cn_df.index.values, dtype="S16")

        gene_attributes.create_dataset("gene_names", data=gene_names)
        cn_cluster_h5.create_dataset("matrix", data=gene_cn_df.values)
        cn_cluster_h5.close()

rule plot_roche_heatmap:
    params:
        roche_genes_path = roche_genes_path,
        bin_size = bin_size
    input:
        cn_cluster_h5 = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_cluster.h5"
    output:
        roche_gene_cn_df = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__roche_cn_gene_df.csv",
        roche_heatmap_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__roche_heatmap_cnvs.png"
    benchmark:
        "benchmark/plot_roche_heatmap.tsv"
    run:
        gene_list = pd.read_csv(params.roche_genes_path, sep="\t", header=None)
        gene_list.columns = ["gene"]
        gene_list = gene_list.gene.values.tolist()

        cn_cluster_h5 = h5py.File(input.cn_cluster_h5, "r")
        cnvs = cn_cluster_h5['matrix']
        gene_names = cn_cluster_h5['gene_attrs']['gene_names'][()].astype(str)

        gene_cn_df = pd.DataFrame(columns=gene_list)
        for gene in gene_list:
            gene_cn_df[gene] = cnvs[np.where(gene_names==gene)[0][0]]
        gene_cn_df = gene_cn_df.T

        gene_cn_df.to_csv(
            output.roche_gene_cn_df
        )

        figure_width = gene_cn_df.shape[0] / 2 + 1.5
        plt.figure(figsize=(8, figure_width))
        cmap = sns.diverging_palette(220, 10, as_cmap=True)
        heatmap = sns.heatmap(
            gene_cn_df,
            annot=True,
            cmap=cmap,
            vmin=0,
            vmax=4,
            xticklabels=True,
            yticklabels=True,
            cbar_kws={"ticks": [0, 1, 2, 3, 4]},
        )
        heatmap.set_title("Copy number values of genes (in Roche's list) per cluster")
        heatmap.set_facecolor("#656565")
        heatmap = heatmap.get_figure()
        heatmap.savefig(
            output.roche_heatmap_cnvs
        )
        plt.close()

rule visualise_trees:
    params:
        highlight_color = config['secondary_analysis']['highlight_color']
    input:
        cluster_tree = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.txt",
        bin_gene_region_df = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bin_gene_region_df.csv",
        genes_to_highlight_path = roche_genes_path
    output:
        cluster_tree_graphviz = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.graphviz",
        cluster_tree_figure =  os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.png",
        cluster_tree_genes_graphviz = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_genes.graphviz",
        cluster_tree_genes_figure =  os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_genes.png"
    run:
        # Tree with region labels
        tree_as_list = tree_to_graphviz(input.cluster_tree)

        for line in tree_as_list:
            print(f"{line}\n")

        with open(output.cluster_tree_graphviz, "w") as file:
            for line in tree_as_list:
                file.write(f"{line}\n")

        try:
            cmd_output = subprocess.run(["dot", "-Tpng", f"{output.cluster_tree_graphviz}", "-o", f"{output.cluster_tree_figure}"])
        except subprocess.SubprocessError as e:
            print("Status : FAIL", e.returncode, e.output, e.stdout, e.stderr)
        else:
            print(f"subprocess out: {cmd_output}")
            print(f"stdout: {cmd_output.stdout}\n stderr: {cmd_output.stderr}")

        # Tree with gene labels
        bin_gene_region_df = pd.read_csv(input.bin_gene_region_df, index_col=0)
        genes_to_highlight = pd.read_csv(input.genes_to_highlight_path, sep="\t", header=None)
        genes_to_highlight.columns = ["gene"]
        genes_to_highlight = genes_to_highlight.gene.values.tolist()
        tree_genes_as_list = tree_to_graphviz(input.cluster_tree, gene_labels=True, bin_gene_region_df=bin_gene_region_df,
                                genes_to_highlight=genes_to_highlight, highlight_color=params.highlight_color)

        for line in tree_genes_as_list:
            print(f"{line}\n")

        with open(output.cluster_tree_genes_graphviz, "w") as file:
            for line in tree_genes_as_list:
                file.write(f"{line}\n")

        try:
            cmd_output = subprocess.run(["dot", "-Tpng", f"{output.cluster_tree_genes_graphviz}", "-o", f"{output.cluster_tree_genes_figure}"])
        except subprocess.SubprocessError as e:
            print("Status : FAIL", e.returncode, e.output, e.stdout, e.stderr)
        else:
            print(f"subprocess out: {cmd_output}")
            print(f"stdout: {cmd_output.stdout}\n stderr: {cmd_output.stderr}")

rule merge_files:
    params:
        fastqs_path = fastqs_path,
	scripts_dir = scripts_dir
    input:
        raw_fastqs = expand('{sample}', sample=raw_fastqs)
    output:
        done = "merge_files_done.txt"
    shell:
        "sh {params.scripts_dir}/merge_10x_gzip_files.sh {params.fastqs_path}; \
	if [ -d {params.fastqs_path}/merged ] ; \
	then \
	    echo merged directory exists;\
	else \
	    mkdir {params.fastqs_path}/merged;\
	fi ; \
        mv {params.fastqs_path}/MERGED_BSSE* {params.fastqs_path}/merged;\
        chmod 775 {params.fastqs_path}/merged/*;\
	touch merge_files_done.txt"


rule rename_fastqs:
    input:
        rules.merge_files.output.done
    output:
        "rename_fastqs_done.txt"
    run:
        merged_fastqs_path = fastqs_path + "/merged/"
	print(merged_fastqs_path)
	fastqs_dir = merged_fastqs_path
	for filename in os.listdir(fastqs_dir):
    	    if filename.startswith("MERGED_BSSE") and filename.endswith('.gz'):
    	        print("old name: " + filename)
                print("new name: " + rename_fastq(filename))
                os.rename(fastqs_dir+filename, fastqs_dir+rename_fastq(filename))
        Path('rename_fastqs_done.txt').touch()

rule trick_fastqs:
    params:
        fastqs_path = fastqs_path,
        scripts_dir = scripts_dir,
        r1 = fastqs_path+"/merged/" + sample_name + "_" + "{lane_no}" + "_R1_001.fastq.gz",
        r2 = fastqs_path+"/merged/" + sample_name + "_" + "{lane_no}" + "_R2_001.fastq.gz",
        mem = config["tricking_fastqs"]["mem"],
        time = config["tricking_fastqs"]["time"]
    input:
        rules.rename_fastqs.output
    output:
        r1_fastqs = os.path.join(moved_fastqs_path, sample_name) + "_" + "{lane_no}" + "_R1_001.fastq.gz"
    shell:
        "\
        if [ -d {params.fastqs_path}/merged/tricked ] ; \
        then \
        echo tricked directory exists;\
        else \
        mkdir {params.fastqs_path}/merged/tricked;\
        fi ;\
        python {params.scripts_dir}/cellranger_dna_trick.py -r1 {params.r1}  -r2 {params.r2} -o {params.fastqs_path}/merged/tricked/"

rule move_fastqs:
    params:
        fastqs_path = fastqs_path,
        sample_name = sample_name
    input:
        tricked_fastqs = expand(os.path.join(moved_fastqs_path, sample_name) + "_" + "{lane_no}" + "_R1_001.fastq.gz", lane_no = fastq_lanes)
    output:
        move_after_tricking_fastqs = "move_fastqs_to_tricked_done.txt"
    shell:
        "mv {params.fastqs_path}/merged/*_R2_* {params.fastqs_path}/merged/tricked/;\
             mv {params.fastqs_path}/merged/*_I1_* {params.fastqs_path}/merged/tricked/;\
                  chmod 755 {params.fastqs_path}/merged/tricked/*;\
                      touch move_fastqs_to_tricked_done.txt;"

rule create_raw_files_list:
    params:
        sym_raw_path = sym_raw_path,
        seq_prefix = seq_prefix
    input:
        sym_r1_fastqs = expand(os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R1_001.fastq.gz", lane_no = fastq_lanes),
        sym_r2_fastqs = expand(os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R2_001.fastq.gz", lane_no = fastq_lanes),
        sym_i1_fastqs = expand(os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_I1_001.fastq.gz", lane_no = fastq_lanes)
    output:
        os.path.join(sym_raw_path, seq_prefix) + "__raw_files.txt"
    shell:
        "cd {params.sym_raw_path}; ls > {params.seq_prefix}__raw_files.txt "

rule create_raw_checksum:
    params:
        sym_raw_path = sym_raw_path,
        seq_prefix = seq_prefix
    input:
        os.path.join(sym_raw_path, seq_prefix) + "__raw_files.txt"
    output:
        checksum_file = os.path.join(sym_raw_path, seq_prefix) + "__raw_files.md5"
    shell:
        "cd {params.sym_raw_path}; find . -exec md5sum '{{}}' \; >  {output.checksum_file}"

rule create_cluster_plots_list:
    params:
        analysis_prefix = analysis_prefix,
        analysis_path = analysis_path
    input:
        secondary_analysis_done = "secondary_analysis_done.txt"
    output:
        cluster_plots_list = os.path.join(analysis_path, "clustering", analysis_prefix ) + "__cluster_profile_files.txt"
    shell:
        "cd {params.analysis_path}/clustering; ls | egrep '{params.analysis_prefix}__cluster_profile_..?\.png' > {params.analysis_prefix}__cluster_profile_files.txt"

rule create_heatmap_plots_list:
    params:
        analysis_prefix = analysis_prefix,
        analysis_path = analysis_path
    input:
        secondary_analysis_done = "secondary_analysis_done.txt"
    output:
        heatmap_plots_list = os.path.join(analysis_path, "clustering", analysis_prefix ) + "__cn_genes_clusters_files.txt"
    shell:
        "cd {params.analysis_path}/clustering; ls | egrep '{params.analysis_prefix}__cn_genes_clusters_chr..?_heatmap\.png' > {params.analysis_prefix}__cn_genes_clusters_files.txt"

rule run_cellranger:
    params:
        fastqs_path = fastqs_path+'/merged/tricked',
        cr_sample_name = cr_sample_name,
        cellranger_path = cellranger_path,
        local_cores = config['cellranger_dna']['local_cores'],
        local_mem = config['cellranger_dna']['local_mem'],
        mem_per_core = config['cellranger_dna']['mem_per_core'],
        mem = config['cellranger_dna']['mem'],
        time = config['cellranger_dna']['time']
    input:
        move_after_tricking_fastqs = "move_fastqs_to_tricked_done.txt",
        reference_path = config['ref_genome_path']
    output:
        cnv_data = os.path.join(cellranger_path, cr_sample_name) + "/outs/cnv_data.h5",
        cellranger_done = "cellranger_done.txt"
    shell:
        'if [ -d {params.cellranger_path}/run ] ; \
        then \
        echo cellranger directory exists;\
        else \
        mkdir {params.cellranger_path}/run;\
        fi ;\
         pushd {params.cellranger_path}/run; cellranger-dna cnv --reference={input.reference_path} --fastqs={params.fastqs_path}\
         --localmem={params.local_mem} --localcores={params.local_cores} --mempercore={params.mem_per_core}\
         --id={params.cr_sample_name} --sample={params.cr_sample_name}; ln -s "{params.cellranger_path}/run/{params.cr_sample_name}/outs/cnv_data.h5"\
         "{params.cellranger_path}/{params.cr_sample_name}/outs/cnv_data.h5"; popd; touch cellranger_done.txt'

rule copy_cellranger_outputs:
    params:
        cr_sample_name = cr_sample_name,
        cellranger_path = cellranger_path,
        analysis_prefix = analysis_prefix
    input:
        cellranger_done = "cellranger_done.txt"
    output:
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__alarms_summary.txt",
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__cnv_data.h5",
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__summary.csv",
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__web_summary.html"
    shell:
        "cd {params.cellranger_path}; \
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/cnv_data.h5'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__cnv_data.h5';\
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/alarms_summary.txt'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__alarms_summary.txt';\
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/summary.csv'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__summary.csv';\
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/web_summary.html'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__web_summary.html';"

rule create_raw_symlinks:
    params:
        seq_prefix = seq_prefix,
        sym_raw_path = sym_raw_path,
        moved_fastqs_path = moved_fastqs_path,
        sample_name = sample_name,
        old_file_name = os.path.join(moved_fastqs_path, sample_name ) + "_"
    input:
        cellranger = "cellranger_done.txt",
        r1_fastqs = os.path.join(moved_fastqs_path, sample_name ) + "_" + "{lane_no}" + "_R1_001.fastq.gz",
        move_after_tricking_fastqs = "move_fastqs_to_tricked_done.txt"
        # r2_fastqs = os.path.join(moved_fastqs_path, sample_name ) + "_" + "{lane_no}" + "_R2_001.fastq.gz",
        # i1_fastqs = os.path.join(moved_fastqs_path, sample_name ) + "_" + "{lane_no}" + "_I1_001.fastq.gz"
    output:
        r1_fastqs = os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R1_001.fastq.gz",
        r2_fastqs = os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R2_001.fastq.gz",
        i1_fastqs = os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_I1_001.fastq.gz"
    shell:
        "ln -s {input.r1_fastqs} {output.r1_fastqs};\
            ln -s {params.old_file_name}{wildcards.lane_no}_R2_001.fastq.gz {output.r2_fastqs};\
                ln -s {params.old_file_name}{wildcards.lane_no}_I1_001.fastq.gz {output.i1_fastqs};"

rule create_derived_symlinks:
    params:
        cellranger_path = cellranger_path,
        analysis_prefix = analysis_prefix,
        ploidy = config["inference"]["ploidy"]
    input:
        cellranger = "cellranger_done.txt",
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv",
        bins_genome = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bins_genome.tsv",
        filtered_counts = os.path.join(analysis_path, "filtering", analysis_prefix ) + "__filtered_counts.csv",
        excluded_bins = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv",
        segmented_regions = os.path.join(analysis_path, "breakpoint_detection", analysis_prefix) + "_segmented_regions.txt",
        segmented_region_sizes = os.path.join(analysis_path, "breakpoint_detection", analysis_prefix) + "_segmented_region_sizes.txt",
        segmented_counts = os.path.join(analysis_path,\
        "breakpoint_detection", analysis_prefix) + "_segmented_counts.csv",
        normalised_bins = os.path.join(analysis_path, "normalisation", analysis_prefix) + "__normalised_bins.csv",
        normalised_regions = os.path.join(analysis_path, "normalisation", analysis_prefix) + "__normalised_regions.csv",
        normalised_bins_clustered_heatmap = os.path.join(analysis_path,\
             "breakpoint_detection", analysis_prefix) + "_normalised_bins_clustered.png",
        normalised_bins_clustered_bps_heatmap = os.path.join(analysis_path,\
             "breakpoint_detection", analysis_prefix) + "_normalised_bins_clustered_bps.png",
        clustering_score = os.path.join(analysis_path, "clustering", analysis_prefix) + "__clustering_score.txt",
        clusters_phenograph_assignment = os.path.join(analysis_path, "clustering", analysis_prefix) + "__clusters_phenograph_assignment.tsv",
        avg_counts = os.path.join(analysis_path,\
                "clustering", analysis_prefix) + "_avg_counts.csv",
        cluster_tree = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.txt",
        cluster_tree_inferred_cnvs = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_cnvs.csv",
        unique_cnv_profiles = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__unique_cluster_tree_cnvs.csv",
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        tree_cluster_sizes =  os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__tree_cluster_sizes.csv",
        overlapping_cluster_plot = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cluster_profile_overlapping.png",
        gene_cn_df = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_gene_df.csv",
        heatmap_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__heatmap_cnvs.png",
        cr_alarms_summary = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__alarms_summary.txt",
        cr_cnv_data = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__cnv_data.h5",
        cr_summary = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__summary.csv",
        cr_web_summary = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__web_summary.html",

    output:
        derived_symlinks = [os.path.join(sym_derived_path, f"{analysis_prefix}__{filename}") for filename in derived_file_names]
    run:

        def create_symlink(source, dest):
            if not os.path.isfile(dest):
                os.symlink(source, dest)
            else:
                os.utime(dest, None)  # Set access/modified times to now

        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__cnv_data.h5", os.path.join(sym_derived_path, f"{analysis_prefix}__cnv_data.h5"))
        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__alarms_summary.txt", os.path.join(sym_derived_path, f"{analysis_prefix}__alarms_summary.txt"))
        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__summary.csv", os.path.join(sym_derived_path, f"{analysis_prefix}__summary.csv"))
        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__web_summary.html", os.path.join(sym_derived_path, f"{analysis_prefix}__web_summary.html"))

        create_symlink(input.chr_stops, os.path.join(sym_derived_path, f"{analysis_prefix}__chr_stops.tsv"))
        create_symlink(input.bins_genome, os.path.join(sym_derived_path, f"{analysis_prefix}__bins_genome.tsv"))
        create_symlink(input.filtered_counts, os.path.join(sym_derived_path, f"{analysis_prefix}__filtered_counts.csv"))

        create_symlink(input.excluded_bins, os.path.join(sym_derived_path, f"{analysis_prefix}__excluded_bins.csv"))

        create_symlink(input.segmented_regions, os.path.join(sym_derived_path, f"{analysis_prefix}__segmented_regions.txt"))
        create_symlink(input.segmented_region_sizes, os.path.join(sym_derived_path, f"{analysis_prefix}__segmented_region_sizes.txt"))
        create_symlink(input.segmented_counts, os.path.join(sym_derived_path, f"{analysis_prefix}__segmented_counts.csv"))

        create_symlink(input.normalised_bins, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_bins.csv"))
        create_symlink(input.normalised_regions, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_regions.csv"))

        create_symlink(input.normalised_bins_clustered_heatmap, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_bins_clustered.png"))
        create_symlink(input.normalised_bins_clustered_bps_heatmap, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_bins_clustered_bps.png"))

        create_symlink(input.clustering_score, os.path.join(sym_derived_path, f"{analysis_prefix}__clustering_score.txt"))
        create_symlink(input.clusters_phenograph_assignment, os.path.join(sym_derived_path, f"{analysis_prefix}__clusters_phenograph_assignment.tsv"))

        create_symlink(input.avg_counts, os.path.join(sym_derived_path, f"{analysis_prefix}__avg_counts.csv"))
        create_symlink(input.cluster_tree, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_tree.txt"))
        create_symlink(input.cluster_tree_inferred_cnvs, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_tree_inferred_cnvs.csv"))
        create_symlink(input.unique_cnv_profiles, os.path.join(sym_derived_path, f"{analysis_prefix}__unique_cluster_tree_cnvs.csv"))
        create_symlink(input.inferred_cnvs, os.path.join(sym_derived_path, f"{analysis_prefix}__inferred_cnvs.csv"))

        create_symlink(input.tree_cluster_sizes, os.path.join(sym_derived_path, f"{analysis_prefix}__tree_cluster_sizes.txt"))
        create_symlink(input.overlapping_cluster_plot, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_profile_overlapping.png"))

        cluster_profile_plots = glob.glob(os.path.join(analysis_path, "inferred_cnvs", f"{analysis_prefix}__cluster_profile_[0-9]*.png"))
        print(cluster_profile_plots)
        with open(os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_profile_files.txt"), "w") as file:
            for cluster_profile_plot in cluster_profile_plots:
                f_name = cluster_profile_plot.split("/")[-1]
                create_symlink(cluster_profile_plot, os.path.join(sym_derived_path, f"{f_name}"))
                file.write(f"{f_name}\n")

        create_symlink(input.gene_cn_df, os.path.join(sym_derived_path, f"{analysis_prefix}__cn_gene_df.csv"))
        create_symlink(input.heatmap_cnvs, os.path.join(sym_derived_path, f"{analysis_prefix}__heatmap_cnvs.png"))

        # write the summary txt
        cn_gene_df = pd.read_csv(input.gene_cn_df, index_col=0)
        n_clusters = len(cn_gene_df.columns)

        amplified_genes = cn_gene_df[(cn_gene_df > params.ploidy).any(axis='columns')].index.values.tolist()
        deleted_genes = cn_gene_df[(cn_gene_df < params.ploidy).any(axis='columns')].index.values.tolist()

        open(os.path.join(sym_derived_path, f"{analysis_prefix}__Summary.txt"), "w").close()
        with open(os.path.join(sym_derived_path, f"{analysis_prefix}__Summary.txt"), "w") as summary_file:
            summary_file.write(f"There are {n_clusters} clones detected with copy number gains in {amplified_genes}"
            f" and copy number deletions in {deleted_genes} among the pre-selected genes.")

rule create_derived_checksum:
    params:
        sym_derived_path = sym_derived_path,
        analysis_prefix = analysis_prefix,
    input:
        derived_symlinks = [os.path.join(sym_derived_path, f"{analysis_prefix}__{filename}") for filename in derived_file_names]
    output:
        checksum_file = os.path.join(sym_derived_path, f"{analysis_prefix}__derived_files.md5")
    shell:
        "cd {params.sym_derived_path}; find . -exec md5sum '{{}}' \; >  {output.checksum_file}"