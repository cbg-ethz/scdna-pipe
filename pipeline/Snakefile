import glob
import os
import h5py
import subprocess
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from tqdm import tqdm
from pathlib import Path
from secondary_analysis import SecondaryAnalysis
from collections import Counter
import re
import warnings
sns.set()

bin_size = config['bin_size']
fastqs_path = config['fastqs_path']
moved_fastqs_path = os.path.join(fastqs_path, "merged", "tricked")
analysis_path = config['analysis_path']

to_upload_path = os.path.join(analysis_path, '..', 'to_upload')
sym_raw_path = os.path.join(to_upload_path, "raw")
sym_derived_path = os.path.join(to_upload_path, "derived")
cellranger_path = os.path.join(analysis_path, "cellranger")
scripts_dir = config['scripts_dir']+'/'
raw_fastqs = glob.glob(fastqs_path + "*.fastq.gz")
fastq_lanes = ["L001","L002","L003","L004"]
sample_name = config['sample_name']
cr_sample_name = sample_name[:-3] # e.g. MHELAVELA_S2 becomes MHELAVELA
h5_path = config['secondary_analysis']['h5_path']
genes_path = config['secondary_analysis']['genes_path']
all_genes_path = config['secondary_analysis']['all_genes_path']
important_genes_path = config['secondary_analysis']['important_genes_path']
roche_genes_path = config['secondary_analysis']['roche_genes_path']

analysis_prefix = config['analysis_prefix']
seq_prefix = config["sequencing_prefix"]

try:
    cluster_tree_rep = config["inference"]["cluster_trees"]["n_reps"]
except KeyError:
    cluster_tree_rep = 10

try:
    full_tree_rep = config["inference"]["full_trees"]["n_reps"]
except KeyError:
    full_tree_rep = 10

derived_file_names = [
            "cnv_data.h5",
            "web_summary.html",
            "summary.csv",
            "alarms_summary.txt",
            "chr_stops.tsv",
            "bins_genome.tsv",
            "filtered_counts.csv",
            "excluded_bins.csv",
            "segmented_regions.txt",
            "segmented_region_sizes.txt",
            "segmented_counts.csv",
            "normalised_bins.csv",
            "normalised_regions.csv",
            "normalised_bins_clustered.png",
            "normalised_bins_clustered_bps.png",
            "clusters_phenograph_assignment.tsv",
            "clustering_score.txt",
            "avg_counts.csv",
            "cluster_tree.txt",
            "cluster_tree_inferred_cnvs.csv",
            "unique_cluster_tree_cnvs.csv",
            "inferred_cnvs.csv",
            "tree_cluster_sizes.txt",
            "cluster_profile_files.txt",
            "cluster_profile_overlapping.png",
            "cn_gene_df.csv",
            "heatmap_cnvs.png",
            "Summary.txt"
        ]

sa = SecondaryAnalysis(
    sample_name=analysis_prefix,
    output_path=analysis_path,
    h5_path=h5_path,
    genes_path=genes_path,
    all_genes_path=all_genes_path,
)

def get_gene_cn_df(genes, cnvs_arr, bin_size, chr_stops):
    """
        Creates and returns the dataframe of copy numbers, genes by cluster ids
        :param genes: The input list of genes to be specified
        :param cnvs_arr: Copy number matrix per cell per bin
        :param bin_size: Integer constant speciying size of each bin
        :param chr_stops: Pandas DataFrame
            Contains the final bins of each chromosome (the df index)
        :return: CN dataframe of genes by clusters
    """
    print(f"genes shape: {genes.shape}")
    print(f"cnvs_arr shape: {cnvs_arr.shape}")
    if len(cnvs_arr.shape) == 1:
            cnvs_arr = cnvs_arr.reshape(1, -1)
    cluster_ids = range(cnvs_arr.shape[0])
    gene_cn_df = pd.DataFrame(index=cluster_ids)

    # for each gene
    for index, row in tqdm(genes.iterrows(), total=genes.shape[0]):
        start_bin = int(row["Gene start (bp)"] / bin_size)
        stop_bin = int(row["Gene end (bp)"] / bin_size)
        chromosome = str(row["Chromosome/scaffold name"])
        gene_name = row["Gene name"]

        if chromosome != '1': # coordinates are given by chromosome
            chr_start = chr_stops.iloc[np.where(chr_stops.index==chromosome)[0][0]-1].values[0] + 1
            start_bin = start_bin + chr_start
            stop_bin = stop_bin + chr_start

        gene_cn_per_cluster = []
        for c_id in cluster_ids:
            cn_states = cnvs_arr[
                c_id, start_bin : stop_bin + 1
            ]
            median_cn_cell_bin = np.nanmedian(
                cn_states
            )  # all the bins within the gene, min due to biology
            gene_cn_per_cluster.append(median_cn_cell_bin)
        gene_cn_df[gene_name] = gene_cn_per_cluster

    print("Transposing the dataframe...")
    gene_cn_df = gene_cn_df.T
    print("Sorting the genes...")
    gene_cn_df.sort_index(inplace=True)

    print(gene_cn_df.head())
    return gene_cn_df

def get_bin_gene_region_df(bin_size, genes, chr_stops, region_stops, bin_is_excluded, important_genes=None):
    """
        Creates a DataFrame with the gene and region corresponding to each bin
        :param bin_size: integer
        :param chr_stops: df indicating the final (unfiltered) bin of each chromosome
        :param region_stops: df indicating the final (filtered) bin of each chromosome
        :param bin_is_excluded: df indicating unmappable bins
        (optional) :param important_genes: list of important genes to be flagged
        :return: DataFrame of (gene, region, original_bin)
    """

    bin_gene_region_df = pd.DataFrame(index=range(chr_stops.iloc[-1].values[0]))
    bin_gene_region_df["gene"] = None
    bin_gene_region_df["chr"] = None
    bin_gene_region_df["region"] = None
    if important_genes is None:
        bin_gene_region_df["is_important"] = True
    else:
        bin_gene_region_df["is_important"] = False

    # for each gene
    for index, row in tqdm(genes.iterrows(), total=genes.shape[0]):
        start_bin = int(row["Gene start (bp)"] / bin_size)
        stop_bin = int(row["Gene end (bp)"] / bin_size)
        chromosome = str(row["Chromosome/scaffold name"])

        if chromosome != '1': # coordinates are given by chromosome
            chr_start = chr_stops.iloc[np.where(chr_stops.index==chromosome)[0][0]-1].values[0] + 1
            start_bin = start_bin + chr_start
            stop_bin = stop_bin + chr_start

        # Check if bins already contain an important gene: if they do, skip
        if (important_genes is None) or ((important_genes is not None) and np.all(bin_gene_region_df.loc[start_bin:stop_bin+1, "is_important"] == False)):
            gene_name = row["Gene name"]
            bin_gene_region_df.loc[start_bin:stop_bin+1, "gene"] = gene_name
            bin_gene_region_df.loc[start_bin:stop_bin+1, "chr"] = chromosome
            if important_genes is not None:
                if gene_name in important_genes:
                    bin_gene_region_df.loc[start_bin:stop_bin+1, "is_important"] = True
                else:
                    # Need this to deal with overlapping gene coordinates
                    bin_gene_region_df.loc[start_bin:stop_bin+1, "is_important"] = False

    # Now we have a (bin, gene) dataframe. Let's remove the unmappable bins
    bin_gene_region_df = bin_gene_region_df.iloc[np.where(bin_is_excluded==0)[0]]

    # Reset the index to indicate new bin indices after filtering
    bin_gene_region_df = bin_gene_region_df.reset_index(drop=False)
    bin_gene_region_df = bin_gene_region_df.rename(columns={"index": "original_bin"})

    # Get the regions
    start_bin = 0
    for index, row in tqdm(region_stops.iterrows(), total=region_stops.shape[0]):
        stop_bin = row.values[0]
        bin_gene_region_df.loc[start_bin:stop_bin+1, "region"] = index # regions are 0 indexed
        start_bin = row.values[0]

    return bin_gene_region_df

def get_genes_in_region(region, bin_gene_region_df, important_only=False):
    """
        Returns a list of genes present in the given region index
        :param region: integer
        :param bin_gene_region_df: DataFrame
            with (gene_name, region, original_bin) fields
        :param important_only: boolean
            indicating if only important genes should be returned
        :return: list of gene names in region
    """
    gene_list = bin_gene_region_df['gene'][
                            np.where(bin_gene_region_df['region']==region)[0]].unique()

    gene_list = gene_list[gene_list != None].tolist()

    if important_only:
        # Subset only the important genes
        important_genes = bin_gene_region_df['gene'][bin_gene_region_df['is_important']].unique()
        gene_list = [str(gene) for gene in gene_list if gene in important_genes]

    return gene_list

def get_region_with_gene(gene, bin_gene_region_df):
    """
        Returns the region index containing a gene
        :param gene: str
        :param bin_gene_region_df: DataFrame
            with (gene_name, region, original_bin) fields
        :return: region index (integer)
    """
    gene = bin_gene_region_df['region'][np.where(bin_gene_region_df['gene']==gene)[0]].values[0]

    return gene

def get_tree_scores(tree_paths):
    """
        Creates the list of tree scores by parsing the tree files
        :param trees_path: a list of tree paths
        :return: the list of tree scores
    """
    tree_scores = []
    for tree_path in tree_paths:
        with open(tree_path) as f:
            list_tree_file = list(f)

        for line in list_tree_file:
            if line.startswith("Tree score:"):
                score = line.rstrip("\n").lstrip("Tree score:").lstrip(" ")
                tree_scores.append(float(score))

    return tree_scores

def rename_fastq(s_name):
    '''
        renames the merged fastqs according to the bcl2fastq naming convention
        Sample input name: MERGED_BSSE_QGF_123456_ZXVN2SHG5_1_QWEERTY_T_scD_250c_r1v1_0_SI-GA-H5_S1_L003_I1_001.fastq.gz
    '''
    split_name = s_name.split('_')
    new_name = '_'.join(split_name[6:7]+split_name[-4:])
    return new_name

def convert_event_region_to_gene(region_event_str, bin_gene_region_df, important_only=False, genes_to_highlight=None, highlight_color='red'):
    """
        Returns a string indicating gene-wise events in affected region
        Examples:
                "+2R174"     -> ["+2BRAF", "+2MALAT1"]
                "-1R656:658" -> ["-1JAK2", "-1MLNA", "-1CDK4"]
        :param region_event_str: str
        :param bin_gene_region_df: DataFrame
            with (gene_name, region, original_bin) fields
        :param important_only: boolean
            indicating if only important genes should be returned
        :param genes_to_highlight: list
            genes that should be displayed in a different color
        :param highlight_color: str
            color to use in genes to highlight
        :return: list of str
    """
    # Get event (-2, -1, +1, +2, etc)
    event_str = region_event_str[:2]
    region_str = region_event_str[3:]
    if ":" in region_str: # multiple regions: "-1R656:658"
        aux = [int(region) for region in region_str.split(":")]
        region_list = np.arange(aux[0], aux[1]+1)
    else:
        region_list = [int(region_str)]

    gene_list = []
    for region in region_list:
        genes_in_region = get_genes_in_region(region, bin_gene_region_df, important_only=important_only)
        gene_list.append(genes_in_region)

    gene_list = [item for sublist in gene_list for item in sublist]

    # Highlight some genes
    if genes_to_highlight is not None:
        for index, gene in enumerate(gene_list):
            if gene in genes_to_highlight:
                gene_list[index] = "<font color=" + "\'" + highlight_color + "\'" + ">" + gene + "</font>"

    gene_string = '[' + ','.join(gene_list) + ']'
    if len(gene_list) == 0:
        gene_event_str = ""
    else:
        gene_event_str = event_str + gene_string

    return gene_event_str

def convert_node_regions_to_genes(node_str, bin_gene_region_df, important_only=False, genes_to_highlight=None, **kwargs):
    """
        Returns a string indicating gene events and total number of
        amplifications and deletions in node
        Examples:
                "+2R174 -1R656:658" -> "+2[BRAF,MALAT1] -1[JAK2,MLNA,CDK4]\n(1+, 1-)"
        :param node_str: str
        :param bin_gene_region_df: DataFrame
            with (gene_name, region, original_bin) fields
        :param important_only: boolean
            indicating if only important genes should be returned
        :param genes_to_highlight: list
            genes that should be displayed in a different color
        :return: str
    """
    region_event_strs = node_str.split(' ')
    num_events = len(region_event_strs)

    num_amplifications = 0
    gene_event_str = []

    for region_event_str in region_event_strs:
        s = convert_event_region_to_gene(region_event_str, bin_gene_region_df,
                important_only=important_only, genes_to_highlight=genes_to_highlight,
                highlight_color=kwargs['highlight_color'])
        gene_event_str.append(s)

        if region_event_str[0]=='+':
            num_amplifications += 1

    gene_event_str = [x for x in gene_event_str if x]
    # Add newline after each x events
    gene_event_str = ' '.join(f"{x}<br/>" if i%2 == 0 and i>0 else str(x) for i, x in enumerate(gene_event_str))
    # gene_event_str = ' '.join(gene_event_str)

    num_deletions = num_events - num_amplifications
    num_events, num_amplifications, num_deletions
    num_events_str = "{} +, {} -".format(num_amplifications, num_deletions)
    num_events_str

    node_str = gene_event_str + " <br/>" + "(" + num_events_str + ")"
    if gene_event_str == "":
        node_str = num_events_str

    return node_str

def tree_to_graphviz(tree_path, gene_labels=False, bin_gene_region_df=None, genes_to_highlight=None, **kwargs):
    """
        reads the file containing trees converts it to graphviz format
        :param tree_path: path to the tree file.
        :param gene_labels: whether to label nodes with genes
        :param bin_gene_region_df: Pandas DataFrame with gene-region correspondence
        :param genes_to_highlight: List containing genes to highlight
        :return: string object containing the graphviz formatted tree
    """
    with open(tree_path) as f:
        list_tree_file = list(f)

    graphviz_header = ["digraph { \n", "node [style=filled,color=\"#D4C0D6\"]"
                "edge [arrowhead=none, color=\"#602A86\"]"]

    graphviz_labels = []
    graphviz_links = []

    graphviz_labels.append("0[label=\"Neutral\"]") # root

    for line in list_tree_file:
        if line.startswith("node 0:"):
            continue
        elif line.startswith("node"):
            comma_splits = line.split(",")

            comma_first = re.split(" |:",comma_splits[0])
            node_id = comma_first[1]
            p_id = comma_first[4]
            comma_rest = comma_splits[1:]
            comma_rest[0] = comma_rest[0].lstrip('[')
            comma_rest[-1] = comma_rest[-1].rstrip(']\n')
            merged_labels = []
            [k_begin, previous_v] = (int(x) for x in comma_rest[0].split(":"))
            k_end = k_begin
            for term in comma_rest[1:]: # events vector
                [k,v] = (int(x) for x in term.split(":"))
                if k==k_end+1 and v==previous_v:
                    k_end = k # update the end
                else:
                    if k_begin == k_end:
                        merged_labels.append(f"{previous_v:+}R{k_begin}")
                    else:
                        merged_labels.append(f"{previous_v:+}R{k_begin}:{k_end}")
                    k_begin = k_end = k
                previous_v = v
            # print the last one
            if k_begin == k_end:
                merged_labels.append(f"{previous_v:+}R{k_begin}")
            else:
                merged_labels.append(f"{previous_v:+}R{k_begin}:{k_end}")

            str_merged_labels = " ".join(f"{x}<br/>" if i%10 == 0 and i>0 else str(x) for i, x in enumerate(merged_labels))
            if gene_labels and bin_gene_region_df is not None:
                node_str = " ".join(merged_labels) # "+1R75 +1R218:219 +1R221:223"
                str_merged_labels = convert_node_regions_to_genes(node_str, bin_gene_region_df,
                                    important_only=True, genes_to_highlight=genes_to_highlight,
                                    **kwargs)

            graphviz_labels.append(f"{node_id}[label=<{str_merged_labels}>]") # use < > to allow HTML
            graphviz_links.append(f"{p_id} -> {node_id}")

    return graphviz_header+graphviz_labels+graphviz_links+["}"]


# import rules
include: os.path.join(workflow.basedir, "rules", "tree_learning.smk")
include: os.path.join(workflow.basedir, "rules", "breakpoint_detection.smk")

onstart:
    print(f"Workflow main directory: {workflow.basedir}")

rule all:
    input:
        # checksums
        raw_checksum_file = os.path.join(sym_raw_path, f"{seq_prefix}__raw_files.md5"),
        derived_checksum_file = os.path.join(sym_derived_path, f"{analysis_prefix}__derived_files.md5"),
        robustness_results = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "_cluster_tree_robustness.txt",

        roche_gene_cn_df = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__roche_cn_gene_df.csv",
        roche_heatmap_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__roche_heatmap_cnvs.png",

        cluster_tree_graphviz = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.graphviz",
        cluster_tree_figure =  os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.png",

        cluster_tree_genes_graphviz = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_genes.graphviz",
        cluster_tree_genes_figure =  os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_genes.png",

        cn_cluster_h5 = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_cluster.h5"
    output:

    run:
        print("echo rule all")

rule remove_tenx_artifacts:
    params:
        bins = config["secondary_analysis"]["bins_to_remove"]
    input:
        os.path.join(cellranger_path, cr_sample_name) + "/outs/cnv_data.h5"
    output:
        filtered_counts = os.path.join(analysis_path, "filtering", analysis_prefix) + "__filtered_counts.csv",
        filtered_counts_shape = os.path.join(analysis_path, "filtering", analysis_prefix) + "__filtered_counts_shape.txt",
        excluded_bins = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv",
    run:
        for key in config['secondary_analysis']:
            assert(os.path.isfile(config['secondary_analysis'][key]))
        sa.remove_tenx_genomics_artifacts(bins=params.bins)

rule extract_genomic_info:
    input:
        os.path.join(cellranger_path, cr_sample_name) + "/outs/cnv_data.h5"
    output:
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv",
        bins_genome = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bins_genome.tsv"
    benchmark:
        "benchmark/extract_genomic_info.tsv"
    run:
        sa.extract_genomic_info()

rule create_bin_gene_region_df:
    input:
        all_genes_path = all_genes_path,
        chr_stops_path = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv",
        excluded_bins_path = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv",
        region_stops_path = os.path.join(analysis_path, "breakpoint_detection", analysis_prefix) + "_segmented_regions.txt",
        important_genes_path = important_genes_path
    params:
        bin_size = bin_size
    output:
        bin_gene_region_df = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bin_gene_region_df.csv"
    benchmark:
        "benchmark/create_bin_gene_region_df.tsv"
    run:
        genes = pd.read_csv(input.all_genes_path, sep="\t")
        chr_stops = pd.read_csv(input.chr_stops_path, sep="\t", index_col=1)
        excluded_bins = pd.read_csv(input.excluded_bins_path, header=None)
        region_stops = pd.read_csv(input.region_stops_path, header=None)
        region_stops.columns = ["bin"]
        important_genes = pd.read_csv(input.important_genes_path, sep="\t", header=None)
        important_genes.columns = ["gene"]
        important_genes = important_genes.gene.values.tolist()

        df = get_bin_gene_region_df(params.bin_size, genes, chr_stops, region_stops, excluded_bins, important_genes=important_genes)
        df.to_csv(output.bin_gene_region_df)

rule add_filtered_bins_back:
    input:
        unique_cnv_profiles = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__unique_cluster_tree_cnvs.csv",
        excluded_bins = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv"
    output:
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv"
    benchmark:
        "benchmark/add_filtered_bins_back.tsv"
    run:
        sa.add_filtered_bins_back(input.unique_cnv_profiles, input.excluded_bins)

rule plot_cluster_cnvs:
    params:
    input:
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv"
    output:
        overlapping_cluster_plot = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cluster_profile_overlapping.png"
    benchmark:
        "benchmark/plot_cluster_cnvs.tsv"
    run:
        sa.plot_clusters(input.chr_stops, input.inferred_cnvs)

rule plot_heatmap:
    params:
        genes_path = config['secondary_analysis']['genes_path'],
        bin_size = bin_size
    input:
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv"
    output:
        gene_cn_df = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_gene_df.csv",
        heatmap_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__heatmap_cnvs.png"
    benchmark:
        "benchmark/plot_heatmap.tsv"
    run:
        cnvs_arr = np.loadtxt(input.inferred_cnvs, delimiter=',')
        genes = pd.read_csv(params.genes_path, sep="\t")
        chr_stops = pd.read_csv(input.chr_stops, sep="\t", index_col=1)
        gene_cn_df = get_gene_cn_df(genes, cnvs_arr, bin_size, chr_stops)

        gene_cn_df.to_csv(
            output.gene_cn_df
        )

        figure_width = gene_cn_df.shape[0] / 2 + 1.5
        plt.figure(figsize=(8, figure_width))
        cmap = sns.diverging_palette(220, 10, as_cmap=True)
        heatmap = sns.heatmap(
            gene_cn_df,
            annot=True,
            cmap=cmap,
            vmin=0,
            vmax=4,
            xticklabels=True,
            yticklabels=True,
            cbar_kws={"ticks": [0, 1, 2, 3, 4]},
        )
        heatmap.set_title("Copy number values of genes per cluster")
        heatmap.set_facecolor("#656565")
        heatmap = heatmap.get_figure()
        heatmap.savefig(
            output.heatmap_cnvs
        )
        plt.close()

rule create_cn_cluster_h5:
    params:
        all_genes_path = all_genes_path,
        bin_size = bin_size
    input:
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv"
    output:
        cn_cluster_h5 = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_cluster.h5"
    benchmark:
        "benchmark/create_cn_cluster_h5"
    run:
        cnvs_arr = np.loadtxt(input.inferred_cnvs, delimiter=',')
        genes = pd.read_csv(params.all_genes_path, sep="\t")
        chr_stops = pd.read_csv(input.chr_stops, sep="\t", index_col=1)

        gene_cn_df = get_gene_cn_df(genes, cnvs_arr, bin_size, chr_stops)

        cn_cluster_h5 = h5py.File(output.cn_cluster_h5, "w")
        gene_attributes = cn_cluster_h5.create_group("gene_attrs")
        gene_names = np.array(gene_cn_df.index.values, dtype="S16")

        gene_attributes.create_dataset("gene_names", data=gene_names)
        cn_cluster_h5.create_dataset("matrix", data=gene_cn_df.values)
        cn_cluster_h5.close()

rule plot_roche_heatmap:
    params:
        roche_genes_path = roche_genes_path,
        bin_size = bin_size
    input:
        cn_cluster_h5 = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_cluster.h5"
    output:
        roche_gene_cn_df = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__roche_cn_gene_df.csv",
        roche_heatmap_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__roche_heatmap_cnvs.png"
    benchmark:
        "benchmark/plot_roche_heatmap.tsv"
    run:
        gene_list = pd.read_csv(params.roche_genes_path, sep="\t", header=None)
        gene_list.columns = ["gene"]
        gene_list = gene_list.gene.values.tolist()

        cn_cluster_h5 = h5py.File(input.cn_cluster_h5, "r")
        cnvs = cn_cluster_h5['matrix']
        gene_names = cn_cluster_h5['gene_attrs']['gene_names'][()].astype(str)

        gene_cn_df = pd.DataFrame(columns=gene_list)
        for gene in gene_list:
            gene_cn_df[gene] = cnvs[np.where(gene_names==gene)[0][0]]
        gene_cn_df = gene_cn_df.T

        gene_cn_df.to_csv(
            output.roche_gene_cn_df
        )

        figure_width = gene_cn_df.shape[0] / 2 + 1.5
        plt.figure(figsize=(8, figure_width))
        cmap = sns.diverging_palette(220, 10, as_cmap=True)
        heatmap = sns.heatmap(
            gene_cn_df,
            annot=True,
            cmap=cmap,
            vmin=0,
            vmax=4,
            xticklabels=True,
            yticklabels=True,
            cbar_kws={"ticks": [0, 1, 2, 3, 4]},
        )
        heatmap.set_title("Copy number values of genes (in Roche's list) per cluster")
        heatmap.set_facecolor("#656565")
        heatmap = heatmap.get_figure()
        heatmap.savefig(
            output.roche_heatmap_cnvs
        )
        plt.close()

rule merge_files:
    params:
        fastqs_path = fastqs_path,
	scripts_dir = scripts_dir
    input:
        raw_fastqs = expand('{sample}', sample=raw_fastqs)
    output:
        done = "merge_files_done.txt"
    shell:
        "sh {params.scripts_dir}/merge_10x_gzip_files.sh {params.fastqs_path}; \
	if [ -d {params.fastqs_path}/merged ] ; \
	then \
	    echo merged directory exists;\
	else \
	    mkdir {params.fastqs_path}/merged;\
	fi ; \
        mv {params.fastqs_path}/MERGED_BSSE* {params.fastqs_path}/merged;\
        chmod 775 {params.fastqs_path}/merged/*;\
	touch merge_files_done.txt"


rule rename_fastqs:
    input:
        rules.merge_files.output.done
    output:
        "rename_fastqs_done.txt"
    run:
        merged_fastqs_path = fastqs_path + "/merged/"
	print(merged_fastqs_path)
	fastqs_dir = merged_fastqs_path
	for filename in os.listdir(fastqs_dir):
    	    if filename.startswith("MERGED_BSSE") and filename.endswith('.gz'):
    	        print("old name: " + filename)
                print("new name: " + rename_fastq(filename))
                os.rename(fastqs_dir+filename, fastqs_dir+rename_fastq(filename))
        Path('rename_fastqs_done.txt').touch()

rule trick_fastqs:
    params:
        fastqs_path = fastqs_path,
        scripts_dir = scripts_dir,
        r1 = fastqs_path+"/merged/" + sample_name + "_" + "{lane_no}" + "_R1_001.fastq.gz",
        r2 = fastqs_path+"/merged/" + sample_name + "_" + "{lane_no}" + "_R2_001.fastq.gz",
        mem = config["tricking_fastqs"]["mem"],
        time = config["tricking_fastqs"]["time"]
    input:
        rules.rename_fastqs.output
    output:
        r1_fastqs = os.path.join(moved_fastqs_path, sample_name) + "_" + "{lane_no}" + "_R1_001.fastq.gz"
    shell:
        "\
        if [ -d {params.fastqs_path}/merged/tricked ] ; \
        then \
        echo tricked directory exists;\
        else \
        mkdir {params.fastqs_path}/merged/tricked;\
        fi ;\
        python {params.scripts_dir}/cellranger_dna_trick.py -r1 {params.r1}  -r2 {params.r2} -o {params.fastqs_path}/merged/tricked/"

rule move_fastqs:
    params:
        fastqs_path = fastqs_path,
        sample_name = sample_name
    input:
        tricked_fastqs = expand(os.path.join(moved_fastqs_path, sample_name) + "_" + "{lane_no}" + "_R1_001.fastq.gz", lane_no = fastq_lanes)
    output:
        move_after_tricking_fastqs = "move_fastqs_to_tricked_done.txt"
    shell:
        "mv {params.fastqs_path}/merged/*_R2_* {params.fastqs_path}/merged/tricked/;\
             mv {params.fastqs_path}/merged/*_I1_* {params.fastqs_path}/merged/tricked/;\
                  chmod 755 {params.fastqs_path}/merged/tricked/*;\
                      touch move_fastqs_to_tricked_done.txt;"

rule create_raw_files_list:
    params:
        sym_raw_path = sym_raw_path,
        seq_prefix = seq_prefix
    input:
        sym_r1_fastqs = expand(os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R1_001.fastq.gz", lane_no = fastq_lanes),
        sym_r2_fastqs = expand(os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R2_001.fastq.gz", lane_no = fastq_lanes),
        sym_i1_fastqs = expand(os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_I1_001.fastq.gz", lane_no = fastq_lanes)
    output:
        os.path.join(sym_raw_path, seq_prefix) + "__raw_files.txt"
    shell:
        "cd {params.sym_raw_path}; ls > {params.seq_prefix}__raw_files.txt "

rule create_raw_checksum:
    params:
        sym_raw_path = sym_raw_path,
        seq_prefix = seq_prefix
    input:
        os.path.join(sym_raw_path, seq_prefix) + "__raw_files.txt"
    output:
        checksum_file = os.path.join(sym_raw_path, seq_prefix) + "__raw_files.md5"
    shell:
        "cd {params.sym_raw_path}; find . -exec md5sum '{{}}' \; >  {output.checksum_file}"

rule create_cluster_plots_list:
    params:
        analysis_prefix = analysis_prefix,
        analysis_path = analysis_path
    input:
        secondary_analysis_done = "secondary_analysis_done.txt"
    output:
        cluster_plots_list = os.path.join(analysis_path, "clustering", analysis_prefix ) + "__cluster_profile_files.txt"
    shell:
        "cd {params.analysis_path}/clustering; ls | egrep '{params.analysis_prefix}__cluster_profile_..?\.png' > {params.analysis_prefix}__cluster_profile_files.txt"

rule create_heatmap_plots_list:
    params:
        analysis_prefix = analysis_prefix,
        analysis_path = analysis_path
    input:
        secondary_analysis_done = "secondary_analysis_done.txt"
    output:
        heatmap_plots_list = os.path.join(analysis_path, "clustering", analysis_prefix ) + "__cn_genes_clusters_files.txt"
    shell:
        "cd {params.analysis_path}/clustering; ls | egrep '{params.analysis_prefix}__cn_genes_clusters_chr..?_heatmap\.png' > {params.analysis_prefix}__cn_genes_clusters_files.txt"

rule run_cellranger:
    params:
        fastqs_path = fastqs_path+'/merged/tricked',
        cr_sample_name = cr_sample_name,
        cellranger_path = cellranger_path,
        local_cores = config['cellranger_dna']['local_cores'],
        local_mem = config['cellranger_dna']['local_mem'],
        mem_per_core = config['cellranger_dna']['mem_per_core'],
        mem = config['cellranger_dna']['mem'],
        time = config['cellranger_dna']['time']
    input:
        move_after_tricking_fastqs = "move_fastqs_to_tricked_done.txt",
        reference_path = config['ref_genome_path']
    output:
        cnv_data = os.path.join(cellranger_path, cr_sample_name) + "/outs/cnv_data.h5",
        cellranger_done = "cellranger_done.txt"
    shell:
        'if [ -d {params.cellranger_path}/run ] ; \
        then \
        echo cellranger directory exists;\
        else \
        mkdir {params.cellranger_path}/run;\
        fi ;\
         pushd {params.cellranger_path}/run; cellranger-dna cnv --reference={input.reference_path} --fastqs={params.fastqs_path}\
         --localmem={params.local_mem} --localcores={params.local_cores} --mempercore={params.mem_per_core}\
         --id={params.cr_sample_name} --sample={params.cr_sample_name}; ln -s "{params.cellranger_path}/run/{params.cr_sample_name}/outs/cnv_data.h5"\
         "{params.cellranger_path}/{params.cr_sample_name}/outs/cnv_data.h5"; popd; touch cellranger_done.txt'

rule copy_cellranger_outputs:
    params:
        cr_sample_name = cr_sample_name,
        cellranger_path = cellranger_path,
        analysis_prefix = analysis_prefix
    input:
        cellranger_done = "cellranger_done.txt"
    output:
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__alarms_summary.txt",
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__cnv_data.h5",
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__summary.csv",
        os.path.join(cellranger_path, "renamed", analysis_prefix) + "__web_summary.html"
    shell:
        "cd {params.cellranger_path}; \
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/cnv_data.h5'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__cnv_data.h5';\
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/alarms_summary.txt'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__alarms_summary.txt';\
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/summary.csv'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__summary.csv';\
         ln -s '{params.cellranger_path}/run/{params.cr_sample_name}/outs/web_summary.html'\
             '{params.cellranger_path}/renamed/{params.analysis_prefix}__web_summary.html';"

rule create_raw_symlinks:
    params:
        seq_prefix = seq_prefix,
        sym_raw_path = sym_raw_path,
        moved_fastqs_path = moved_fastqs_path,
        sample_name = sample_name,
        old_file_name = os.path.join(moved_fastqs_path, sample_name ) + "_"
    input:
        cellranger = "cellranger_done.txt",
        r1_fastqs = os.path.join(moved_fastqs_path, sample_name ) + "_" + "{lane_no}" + "_R1_001.fastq.gz",
        move_after_tricking_fastqs = "move_fastqs_to_tricked_done.txt"
        # r2_fastqs = os.path.join(moved_fastqs_path, sample_name ) + "_" + "{lane_no}" + "_R2_001.fastq.gz",
        # i1_fastqs = os.path.join(moved_fastqs_path, sample_name ) + "_" + "{lane_no}" + "_I1_001.fastq.gz"
    output:
        r1_fastqs = os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R1_001.fastq.gz",
        r2_fastqs = os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_R2_001.fastq.gz",
        i1_fastqs = os.path.join(sym_raw_path, seq_prefix) + "__" + "{lane_no}" + "_I1_001.fastq.gz"
    shell:
        "ln -s {input.r1_fastqs} {output.r1_fastqs};\
            ln -s {params.old_file_name}{wildcards.lane_no}_R2_001.fastq.gz {output.r2_fastqs};\
                ln -s {params.old_file_name}{wildcards.lane_no}_I1_001.fastq.gz {output.i1_fastqs};"

rule create_derived_symlinks:
    params:
        cellranger_path = cellranger_path,
        analysis_prefix = analysis_prefix,
        ploidy = config["inference"]["ploidy"]
    input:
        cellranger = "cellranger_done.txt",
        chr_stops = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__chr_stops.tsv",
        bins_genome = os.path.join(analysis_path, "genomic_coordinates", analysis_prefix) + "__bins_genome.tsv",
        filtered_counts = os.path.join(analysis_path, "filtering", analysis_prefix ) + "__filtered_counts.csv",
        excluded_bins = os.path.join(analysis_path, "filtering", analysis_prefix) + "__excluded_bins.csv",
        segmented_regions = os.path.join(analysis_path, "breakpoint_detection", analysis_prefix) + "_segmented_regions.txt",
        segmented_region_sizes = os.path.join(analysis_path, "breakpoint_detection", analysis_prefix) + "_segmented_region_sizes.txt",
        segmented_counts = os.path.join(analysis_path,\
        "breakpoint_detection", analysis_prefix) + "_segmented_counts.csv",
        normalised_bins = os.path.join(analysis_path, "normalisation", analysis_prefix) + "__normalised_bins.csv",
        normalised_regions = os.path.join(analysis_path, "normalisation", analysis_prefix) + "__normalised_regions.csv",
        normalised_bins_clustered_heatmap = os.path.join(analysis_path,\
             "breakpoint_detection", analysis_prefix) + "_normalised_bins_clustered.png",
        normalised_bins_clustered_bps_heatmap = os.path.join(analysis_path,\
             "breakpoint_detection", analysis_prefix) + "_normalised_bins_clustered_bps.png",
        clustering_score = os.path.join(analysis_path, "clustering", analysis_prefix) + "__clustering_score.txt",
        clusters_phenograph_assignment = os.path.join(analysis_path, "clustering", analysis_prefix) + "__clusters_phenograph_assignment.tsv",
        avg_counts = os.path.join(analysis_path,\
                "clustering", analysis_prefix) + "_avg_counts.csv",
        cluster_tree = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree.txt",
        cluster_tree_inferred_cnvs = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__cluster_tree_cnvs.csv",
        unique_cnv_profiles = os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__unique_cluster_tree_cnvs.csv",
        inferred_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__inferred_cnvs.csv",
        tree_cluster_sizes =  os.path.join(analysis_path, "tree_learning", analysis_prefix) + "__tree_cluster_sizes.csv",
        overlapping_cluster_plot = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cluster_profile_overlapping.png",
        gene_cn_df = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__cn_gene_df.csv",
        heatmap_cnvs = os.path.join(analysis_path, "inferred_cnvs", analysis_prefix) + "__heatmap_cnvs.png",
        cr_alarms_summary = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__alarms_summary.txt",
        cr_cnv_data = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__cnv_data.h5",
        cr_summary = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__summary.csv",
        cr_web_summary = os.path.join(cellranger_path, "renamed", analysis_prefix) + "__web_summary.html",

    output:
        derived_symlinks = [os.path.join(sym_derived_path, f"{analysis_prefix}__{filename}") for filename in derived_file_names]
    run:

        def create_symlink(source, dest):
            if not os.path.isfile(dest):
                os.symlink(source, dest)
            else:
                os.utime(dest, None)  # Set access/modified times to now

        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__cnv_data.h5", os.path.join(sym_derived_path, f"{analysis_prefix}__cnv_data.h5"))
        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__alarms_summary.txt", os.path.join(sym_derived_path, f"{analysis_prefix}__alarms_summary.txt"))
        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__summary.csv", os.path.join(sym_derived_path, f"{analysis_prefix}__summary.csv"))
        create_symlink(os.path.join(cellranger_path, "renamed", analysis_prefix) + "__web_summary.html", os.path.join(sym_derived_path, f"{analysis_prefix}__web_summary.html"))

        create_symlink(input.chr_stops, os.path.join(sym_derived_path, f"{analysis_prefix}__chr_stops.tsv"))
        create_symlink(input.bins_genome, os.path.join(sym_derived_path, f"{analysis_prefix}__bins_genome.tsv"))
        create_symlink(input.filtered_counts, os.path.join(sym_derived_path, f"{analysis_prefix}__filtered_counts.csv"))

        create_symlink(input.excluded_bins, os.path.join(sym_derived_path, f"{analysis_prefix}__excluded_bins.csv"))

        create_symlink(input.segmented_regions, os.path.join(sym_derived_path, f"{analysis_prefix}__segmented_regions.txt"))
        create_symlink(input.segmented_region_sizes, os.path.join(sym_derived_path, f"{analysis_prefix}__segmented_region_sizes.txt"))
        create_symlink(input.segmented_counts, os.path.join(sym_derived_path, f"{analysis_prefix}__segmented_counts.csv"))

        create_symlink(input.normalised_bins, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_bins.csv"))
        create_symlink(input.normalised_regions, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_regions.csv"))

        create_symlink(input.normalised_bins_clustered_heatmap, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_bins_clustered.png"))
        create_symlink(input.normalised_bins_clustered_bps_heatmap, os.path.join(sym_derived_path, f"{analysis_prefix}__normalised_bins_clustered_bps.png"))

        create_symlink(input.clustering_score, os.path.join(sym_derived_path, f"{analysis_prefix}__clustering_score.txt"))
        create_symlink(input.clusters_phenograph_assignment, os.path.join(sym_derived_path, f"{analysis_prefix}__clusters_phenograph_assignment.tsv"))

        create_symlink(input.avg_counts, os.path.join(sym_derived_path, f"{analysis_prefix}__avg_counts.csv"))
        create_symlink(input.cluster_tree, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_tree.txt"))
        create_symlink(input.cluster_tree_inferred_cnvs, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_tree_inferred_cnvs.csv"))
        create_symlink(input.unique_cnv_profiles, os.path.join(sym_derived_path, f"{analysis_prefix}__unique_cluster_tree_cnvs.csv"))
        create_symlink(input.inferred_cnvs, os.path.join(sym_derived_path, f"{analysis_prefix}__inferred_cnvs.csv"))

        create_symlink(input.tree_cluster_sizes, os.path.join(sym_derived_path, f"{analysis_prefix}__tree_cluster_sizes.txt"))
        create_symlink(input.overlapping_cluster_plot, os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_profile_overlapping.png"))

        cluster_profile_plots = glob.glob(os.path.join(analysis_path, "inferred_cnvs", f"{analysis_prefix}__cluster_profile_[0-9]*.png"))
        print(cluster_profile_plots)
        with open(os.path.join(sym_derived_path, f"{analysis_prefix}__cluster_profile_files.txt"), "w") as file:
            for cluster_profile_plot in cluster_profile_plots:
                f_name = cluster_profile_plot.split("/")[-1]
                create_symlink(cluster_profile_plot, os.path.join(sym_derived_path, f"{f_name}"))
                file.write(f"{f_name}\n")

        create_symlink(input.gene_cn_df, os.path.join(sym_derived_path, f"{analysis_prefix}__cn_gene_df.csv"))
        create_symlink(input.heatmap_cnvs, os.path.join(sym_derived_path, f"{analysis_prefix}__heatmap_cnvs.png"))

        # write the summary txt
        cn_gene_df = pd.read_csv(input.gene_cn_df, index_col=0)
        n_clusters = len(cn_gene_df.columns)

        amplified_genes = cn_gene_df[(cn_gene_df > params.ploidy).any(axis='columns')].index.values.tolist()
        deleted_genes = cn_gene_df[(cn_gene_df < params.ploidy).any(axis='columns')].index.values.tolist()

        open(os.path.join(sym_derived_path, f"{analysis_prefix}__Summary.txt"), "w").close()
        with open(os.path.join(sym_derived_path, f"{analysis_prefix}__Summary.txt"), "w") as summary_file:
            summary_file.write(f"There are {n_clusters} clones detected with copy number gains in {amplified_genes}"
            f" and copy number deletions in {deleted_genes} among the pre-selected genes.")

rule create_derived_checksum:
    params:
        sym_derived_path = sym_derived_path,
        analysis_prefix = analysis_prefix,
    input:
        derived_symlinks = [os.path.join(sym_derived_path, f"{analysis_prefix}__{filename}") for filename in derived_file_names]
    output:
        checksum_file = os.path.join(sym_derived_path, f"{analysis_prefix}__derived_files.md5")
    shell:
        "cd {params.sym_derived_path}; find . -exec md5sum '{{}}' \; >  {output.checksum_file}"